{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from dotenv import load_dotenv\n",
    "from os import getenv\n",
    "from pathlib import Path\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "import findspark\n",
    "\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CWD: Path = Path(\"/app/\")\n",
    "EXAMPLE_INPUT_PATH: Path = CWD / Path(\"./coding_challenge_files/example_input.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAST PART TWO MYSQL DB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database Config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we setup the connector driver path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MYSQL_CONNECTOR_FILENAME: str = \"mysql-connector-j-8.2.0.jar\"\n",
    "MYSQL_CONNECTOR_PATH: str = f\"/app/mysql_connector/{MYSQL_CONNECTOR_FILENAME}\"\n",
    "TABLE_NAME: str = \"INSTRUMENT_PRICE_MODIFIER\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check if hte connector path is correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(MYSQL_CONNECTOR_PATH).exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we move the connector driver in the proper place in order to be recognizable by pyspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.add_jars(MYSQL_CONNECTOR_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We setup the relevant credentials for the database connection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user': 'root',\n",
       " 'password': 'example',\n",
       " 'host': 'db',\n",
       " 'port': 3306,\n",
       " 'database': 'mydb'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# database connection info\n",
    "DB_CON_DICT = dict(\n",
    "    user=getenv(\"MYSQL_ROOT_USER\"),\n",
    "    password=getenv(\"MYSQL_ROOT_PASSWORD\"),\n",
    "    host=getenv(\"HOST\"),\n",
    "    port=int(getenv(\"MYSQL_DOCKER_PORT\")),  # type: ignore\n",
    "    database=getenv(\"MYSQL_DATABASE\"),\n",
    ")\n",
    "\n",
    "DB_CON_DICT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also setup the pyspark specific format we need for the database connection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'driver': 'com.mysql.cj.jdbc.Driver',\n",
       " 'url': 'jdbc:mysql://db:3306/mydb',\n",
       " 'user': 'root',\n",
       " 'password': 'example'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure MySQL connection properties\n",
    "MYSQL_PROPERTIES = {\n",
    "    \"driver\": \"com.mysql.cj.jdbc.Driver\",\n",
    "    \"url\": \"jdbc:mysql://{host}:{port}/{database}\".format(**DB_CON_DICT),  # type: ignore\n",
    "    \"user\": DB_CON_DICT[\"user\"],  # type: ignore\n",
    "    \"password\": DB_CON_DICT[\"password\"],  # type: ignore\n",
    "}\n",
    "\n",
    "MYSQL_PROPERTIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test the database connection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tests.src import test_mysql_conx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection Success\n"
     ]
    }
   ],
   "source": [
    "# test database connection\n",
    "test_mysql_conx(**DB_CON_DICT)  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a test table with some values for pyspark database test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tests.src import table_preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'test_table' deleted successfully.\n",
      "Table 'test_table' created successfully.\n",
      "Sample data inserted successfully.\n"
     ]
    }
   ],
   "source": [
    "table_preparation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test the pyspark session against this test_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tests.src import test_pyspark_db_conx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MYSQL_PROPERTIES={'driver': 'com.mysql.cj.jdbc.Driver', 'url': 'jdbc:mysql://db:3306/mydb', 'user': 'root', 'password': 'example'}\n",
      "MYSQL driver path existence: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/01/11 17:37:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| id| name|\n",
      "+---+-----+\n",
      "|  1| John|\n",
      "|  2|Alice|\n",
      "|  3|  Bob|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_pyspark_db_conx()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We clean up the test_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tests.src import drop_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'test_table' deleted successfully.\n"
     ]
    }
   ],
   "source": [
    "drop_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `So as part of your task we would like you to set up a database with only one table, called INSTRUMENT_PRICE_MODIFIER with the following columns:`\n",
    "\n",
    "-   ID (primary key)\n",
    "-   NAME (instrument name as read from the input file)\n",
    "-   MULTIPLIER - double value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"DatabaseConnection\")\n",
    "    .config(\"spark.jars\", MYSQL_CONNECTOR_PATH)\n",
    "    .config(\"spark.driver.extraClassPath\", MYSQL_CONNECTOR_PATH)\n",
    "    .config(\"spark.executor.extraClassPath\", MYSQL_CONNECTOR_PATH)\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create the schema for the table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    IntegerType,\n",
    "    StringType,\n",
    "    DoubleType,\n",
    ")\n",
    "\n",
    "# Define the schema\n",
    "SCHEMA_DB = StructType(\n",
    "    [\n",
    "        StructField(\n",
    "            \"ID\", IntegerType(), False\n",
    "        ),  # False indicates that the field is not nullable\n",
    "        StructField(\n",
    "            \"NAME\", StringType(), True\n",
    "        ),  # True indicates that the field is nullable\n",
    "        StructField(\"MULTIPLIER\", DoubleType(), True),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing purposes we generate some dummy data, WITHOUT INSTRUMENT1, INSTRUMENT3 for the sake of realistic example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from random import uniform, randint\n",
    "\n",
    "# Generate test data\n",
    "# num_rows = 20\n",
    "# data = [\n",
    "#     (i, f\"INSTRUMENT{choice([2,4,5,6])}\", round(uniform(1.0, 10.0), 2))\n",
    "#     for i in range(1, num_rows + 1)\n",
    "# ]\n",
    "\n",
    "data: list[tuple[int, str, float]] = [\n",
    "    (1, \"INSTRUMENT5\", 5.19),\n",
    "    (2, \"INSTRUMENT4\", 5.05),\n",
    "    (3, \"INSTRUMENT2\", 4.4),\n",
    "    (4, \"INSTRUMENT4\", 2.25),\n",
    "    (5, \"INSTRUMENT5\", 1.75),\n",
    "    (6, \"INSTRUMENT6\", 9.91),\n",
    "    (7, \"INSTRUMENT4\", 4.5),\n",
    "    (8, \"INSTRUMENT2\", 9.24),\n",
    "    (9, \"INSTRUMENT6\", 5.83),\n",
    "    (10, \"INSTRUMENT5\", 1.34),\n",
    "    (11, \"INSTRUMENT6\", 8.89),\n",
    "    (12, \"INSTRUMENT2\", 2.59),\n",
    "    (13, \"INSTRUMENT5\", 4.04),\n",
    "    (14, \"INSTRUMENT4\", 8.58),\n",
    "    (15, \"INSTRUMENT2\", 8.64),\n",
    "    (16, \"INSTRUMENT2\", 3.99),\n",
    "    (17, \"INSTRUMENT2\", 6.82),\n",
    "    (18, \"INSTRUMENT2\", 7.7),\n",
    "    (19, \"INSTRUMENT4\", 4.44),\n",
    "    (20, \"INSTRUMENT4\", 8.01),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = false)\n",
      " |-- NAME: string (nullable = true)\n",
      " |-- MULTIPLIER: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                        (0 + 12) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+----------+\n",
      "| ID|       NAME|MULTIPLIER|\n",
      "+---+-----------+----------+\n",
      "|  1|INSTRUMENT5|      5.19|\n",
      "|  2|INSTRUMENT4|      5.05|\n",
      "|  3|INSTRUMENT2|       4.4|\n",
      "|  4|INSTRUMENT4|      2.25|\n",
      "|  5|INSTRUMENT5|      1.75|\n",
      "+---+-----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(data, schema=SCHEMA_DB).orderBy(\"ID\")\n",
    "\n",
    "df.printSchema()\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Write the DataFrame to MySQL\n",
    "df.write.jdbc(\n",
    "    url=MYSQL_PROPERTIES[\"url\"],\n",
    "    table=TABLE_NAME,\n",
    "    mode=\"overwrite\",  # or \"append\" if needed\n",
    "    properties=MYSQL_PROPERTIES,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determination of the final value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 `read the line from the input file;`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the .txt file\n",
    "txt_file_path: str = f\"{EXAMPLE_INPUT_PATH}\"\n",
    "\n",
    "# Define the schema with StringType for DATE initially\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField(name=\"INSTRUMENT_NAME\", dataType=StringType(), nullable=True),\n",
    "        StructField(name=\"DATE\", dataType=StringType(), nullable=True),\n",
    "        StructField(name=\"VALUE\", dataType=DoubleType(), nullable=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Read the .txt file into a PySpark DataFrame\n",
    "extr = spark.read.option(\"delimiter\", \",\").csv(\n",
    "    txt_file_path, header=False, schema=schema\n",
    ")\n",
    "\n",
    "# transform to dataframe\n",
    "df_txt = extr.toDF(\"INSTRUMENT_NAME\", \"DATE\", \"VALUE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- INSTRUMENT_NAME: string (nullable = true)\n",
      " |-- DATE: string (nullable = true)\n",
      " |-- VALUE: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------+------+\n",
      "|INSTRUMENT_NAME|       DATE| VALUE|\n",
      "+---------------+-----------+------+\n",
      "|    INSTRUMENT1|01-Jan-1996|2.4655|\n",
      "|    INSTRUMENT1|02-Jan-1996|2.4685|\n",
      "|    INSTRUMENT1|03-Jan-1996| 2.473|\n",
      "|    INSTRUMENT1|04-Jan-1996|2.4845|\n",
      "|    INSTRUMENT1|05-Jan-1996|2.4868|\n",
      "+---------------+-----------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_txt.printSchema()\n",
    "\n",
    "df_txt.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming that the data is sanitized and preprocessed as in task_part_1.ipynb we proceed with the objectives of the second part and extract all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(INSTRUMENT_NAME='INSTRUMENT1', DATE='01-Jan-1996', VALUE=2.4655),\n",
       " Row(INSTRUMENT_NAME='INSTRUMENT1', DATE='02-Jan-1996', VALUE=2.4685),\n",
       " Row(INSTRUMENT_NAME='INSTRUMENT1', DATE='03-Jan-1996', VALUE=2.473),\n",
       " Row(INSTRUMENT_NAME='INSTRUMENT1', DATE='04-Jan-1996', VALUE=2.4845),\n",
       " Row(INSTRUMENT_NAME='INSTRUMENT1', DATE='05-Jan-1996', VALUE=2.4868)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = df_txt.collect()\n",
    "rows[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constructing the Solution\n",
    "\n",
    "`query the database to see if there is an entry for the <INSTRUMENT_NAME> you read in the 0st step;`\n",
    "\n",
    "`if there is - multiply the original <VALUE> by the factor you found in the step 2;`\n",
    "\n",
    "`if there is no entry - simply use the original <VALUE> from the file`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rough idea is the following for a couple of rows. For our example we cherry pick a couple of rows from each INSTRUMENT name we have on the .txt file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(INSTRUMENT_NAME='INSTRUMENT1', DATE='01-Jan-1996', VALUE=2.4655),\n",
       " Row(INSTRUMENT_NAME='INSTRUMENT1', DATE='02-Jan-1996', VALUE=2.4685)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_1 = [row for row in rows if row[\"INSTRUMENT_NAME\"] == \"INSTRUMENT1\"][:2]\n",
    "l_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(INSTRUMENT_NAME='INSTRUMENT2', DATE='22-Feb-1996', VALUE=9.326787847),\n",
       " Row(INSTRUMENT_NAME='INSTRUMENT2', DATE='23-Feb-1996', VALUE=9.321527686)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_2 = [row for row in rows if row[\"INSTRUMENT_NAME\"] == \"INSTRUMENT2\"][:2]\n",
    "l_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(INSTRUMENT_NAME='INSTRUMENT3', DATE='31-May-2012', VALUE=78.5325),\n",
       " Row(INSTRUMENT_NAME='INSTRUMENT3', DATE='01-Jun-2012', VALUE=78.2655)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_3 = [row for row in rows if row[\"INSTRUMENT_NAME\"] == \"INSTRUMENT3\"][:2]\n",
    "l_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_list = l_1 + l_2 + l_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We engineered our database to not include INSTRUMENT1 for this example to be realistic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='INSTRUMENT1'\n",
      "Initial value: 2.4655\n",
      "No Multiplier found\n",
      "final_value=2.4655\n",
      "-----------------------------\n",
      "name='INSTRUMENT1'\n",
      "Initial value: 2.4685\n",
      "No Multiplier found\n",
      "final_value=2.4685\n",
      "-----------------------------\n",
      "name='INSTRUMENT2'\n",
      "Initial value: 9.326787847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiplier found: 4.4\n",
      "final_value=41.0378665268\n",
      "-----------------------------\n",
      "name='INSTRUMENT2'\n",
      "Initial value: 9.321527686\n",
      "Multiplier found: 4.4\n",
      "final_value=41.0147218184\n",
      "-----------------------------\n",
      "name='INSTRUMENT3'\n",
      "Initial value: 78.5325\n",
      "No Multiplier found\n",
      "final_value=78.5325\n",
      "-----------------------------\n",
      "name='INSTRUMENT3'\n",
      "Initial value: 78.2655\n",
      "No Multiplier found\n",
      "final_value=78.2655\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "# create an empty dataframe\n",
    "result_df = spark.createDataFrame([], schema=SCHEMA_DB)\n",
    "\n",
    "# let's see the first 10\n",
    "for row in example_list:\n",
    "    # check if the name is empty\n",
    "    if name := row[\"INSTRUMENT_NAME\"]:\n",
    "        # if not we proceed with querying the database\n",
    "        query: str = f\"SELECT * FROM {TABLE_NAME} WHERE NAME = '{name}'\"\n",
    "\n",
    "        # Query the database\n",
    "        result_df = (\n",
    "            spark.read.format(\"jdbc\").options(**MYSQL_PROPERTIES, query=query).load()\n",
    "        )\n",
    "        print(f\"{name=}\")\n",
    "        print(f'Initial value: {row[\"VALUE\"]}')\n",
    "\n",
    "    # is there is match in the database\n",
    "    if not result_df.isEmpty():\n",
    "        print(f\"Multiplier found: {result_df.collect()[0]['MULTIPLIER']}\")\n",
    "        final_value = row[\"VALUE\"] * result_df.collect()[0][\"MULTIPLIER\"]\n",
    "        print(f\"{final_value=}\")\n",
    "    # if there is no match in the database\n",
    "    else:\n",
    "        print(\"No Multiplier found\")\n",
    "        final_value = row[\"VALUE\"]\n",
    "        print(f\"{final_value=}\")\n",
    "    print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the rough idea works just fine. Let us refine it by properly introducing a proper query mechanism according to the specifications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the query is pretty simple and the table is supposed to be GBs it is much more efficient to directly query the database with the instrument name in order to obtain our result.\n",
    "\n",
    "-   This really depends on how powerful is the pyspark cluster or the database itself.\n",
    "-   We assume that direct query to the database consumes the least resources in this case.\n",
    "\n",
    "Regarding the time frequency of our queries, we will use a guard condition that will return the results of the previous query if we are within the 5 seconds time-window and the previous instrument name is the same as the current instrument name. Otherwise a new query will issued on the database.\n",
    "\n",
    "This construction will be realized using the notion of a closure. A closure very roughly is a function with memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "\n",
    "DB_MIN_UPDATE_TIME = 5  # secs\n",
    "\n",
    "\n",
    "def handle_query(instrument_name):\n",
    "    \"\"\"helper function to query a specific instrument in the db\"\"\"\n",
    "    query: str = f\"SELECT * FROM {TABLE_NAME} WHERE NAME = '{instrument_name}'\"\n",
    "\n",
    "    # Query the database\n",
    "    return spark.read.format(\"jdbc\").options(**MYSQL_PROPERTIES, query=query).load()\n",
    "\n",
    "\n",
    "def query_db_closure(verbose: bool = False):\n",
    "    result_df = spark.createDataFrame([], schema=SCHEMA_DB)\n",
    "    last_time: datetime = datetime.now(timezone.utc)\n",
    "    last_instrument_name: str = \"\"\n",
    "    \n",
    "    # this is a bookmark\n",
    "    # of how many times the function\n",
    "    # query_db has been called\n",
    "    call_counter = 1\n",
    "\n",
    "    def query_db(instrument_name: str):\n",
    "        # this is to make the variables\n",
    "        # available to the upper scope of\n",
    "        # which is query_db_closure\n",
    "        nonlocal result_df, last_time, last_instrument_name, call_counter\n",
    "\n",
    "        current_time: datetime = datetime.now(timezone.utc)\n",
    "        timediff: int = (current_time - last_time).seconds\n",
    "\n",
    "        # printing logs\n",
    "        if verbose:\n",
    "            print(\"----query_db----\")\n",
    "            print(f\"{last_instrument_name=}, current_instrument_name={instrument_name}\")\n",
    "            print(f\"{call_counter=}\")\n",
    "\n",
    "        # this is a guard condition that ensures\n",
    "        # we query the database a maximum of once\n",
    "        # every 5 seconds for the same instrument\n",
    "        if timediff <= DB_MIN_UPDATE_TIME and (last_instrument_name == instrument_name):\n",
    "            if verbose:\n",
    "                current_time_str: str = datetime.strftime(\n",
    "                    current_time, \"%d/%m/%Y, %H:%M:%S\"\n",
    "                )\n",
    "                print(f\"SAME Q {current_time_str}, {timediff=}\")\n",
    "                print(\" \")\n",
    "            last_time = current_time\n",
    "            last_instrument_name = instrument_name\n",
    "            call_counter += 1\n",
    "            return result_df\n",
    "\n",
    "        # printing logs\n",
    "        if verbose:\n",
    "            current_time_str: str = datetime.strftime(\n",
    "                current_time, \"%d/%m/%Y, %H:%M:%S\"\n",
    "            )\n",
    "            print(f\"NEW Q {current_time_str}, {timediff=}\")\n",
    "            print(\" \")\n",
    "\n",
    "        # query database\n",
    "        result_df = handle_query(instrument_name)\n",
    "\n",
    "        last_time = current_time\n",
    "        last_instrument_name = instrument_name\n",
    "        call_counter += 1\n",
    "        return result_df\n",
    "\n",
    "    return query_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this first with the exact same instruments all over\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['INSTRUMENT1',\n",
       " 'INSTRUMENT1',\n",
       " 'INSTRUMENT1',\n",
       " 'INSTRUMENT1',\n",
       " 'INSTRUMENT1',\n",
       " 'INSTRUMENT1',\n",
       " 'INSTRUMENT1',\n",
       " 'INSTRUMENT1',\n",
       " 'INSTRUMENT1',\n",
       " 'INSTRUMENT1',\n",
       " 'INSTRUMENT1',\n",
       " 'INSTRUMENT1',\n",
       " 'INSTRUMENT1',\n",
       " 'INSTRUMENT1',\n",
       " 'INSTRUMENT1']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dummy_instrument_list = [f\"INSTRUMENT{choice([1, 1])}\" for i in range(1, 100)]\n",
    "\n",
    "dummy_instrument_list: list[str] = [\n",
    "    \"INSTRUMENT1\",\n",
    "    \"INSTRUMENT1\",\n",
    "    \"INSTRUMENT1\",\n",
    "    \"INSTRUMENT1\",\n",
    "    \"INSTRUMENT1\",\n",
    "    \"INSTRUMENT1\",\n",
    "    \"INSTRUMENT1\",\n",
    "    \"INSTRUMENT1\",\n",
    "    \"INSTRUMENT1\",\n",
    "    \"INSTRUMENT1\",\n",
    "    \"INSTRUMENT1\",\n",
    "    \"INSTRUMENT1\",\n",
    "    \"INSTRUMENT1\",\n",
    "    \"INSTRUMENT1\",\n",
    "    \"INSTRUMENT1\",\n",
    "]\n",
    "\n",
    "dummy_instrument_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should encouter NEW Q (new querries) only when timediff > 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----query_db----\n",
      "last_instrument_name='', current_instrument_name=INSTRUMENT1\n",
      "call_counter=1\n",
      "NEW Q 11/01/2024, 17:37:32, timediff=6\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT1', current_instrument_name=INSTRUMENT1\n",
      "call_counter=2\n",
      "NEW Q 11/01/2024, 17:37:41, timediff=9\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT1', current_instrument_name=INSTRUMENT1\n",
      "call_counter=3\n",
      "NEW Q 11/01/2024, 17:37:50, timediff=9\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT1', current_instrument_name=INSTRUMENT1\n",
      "call_counter=4\n",
      "SAME Q 11/01/2024, 17:37:54, timediff=4\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT1', current_instrument_name=INSTRUMENT1\n",
      "call_counter=5\n",
      "SAME Q 11/01/2024, 17:37:59, timediff=5\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT1', current_instrument_name=INSTRUMENT1\n",
      "call_counter=6\n",
      "SAME Q 11/01/2024, 17:38:02, timediff=3\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT1', current_instrument_name=INSTRUMENT1\n",
      "call_counter=7\n",
      "SAME Q 11/01/2024, 17:38:04, timediff=2\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT1', current_instrument_name=INSTRUMENT1\n",
      "call_counter=8\n",
      "NEW Q 11/01/2024, 17:38:13, timediff=9\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT1', current_instrument_name=INSTRUMENT1\n",
      "call_counter=9\n",
      "NEW Q 11/01/2024, 17:38:20, timediff=7\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT1', current_instrument_name=INSTRUMENT1\n",
      "call_counter=10\n",
      "SAME Q 11/01/2024, 17:38:25, timediff=5\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT1', current_instrument_name=INSTRUMENT1\n",
      "call_counter=11\n",
      "SAME Q 11/01/2024, 17:38:27, timediff=2\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT1', current_instrument_name=INSTRUMENT1\n",
      "call_counter=12\n",
      "NEW Q 11/01/2024, 17:38:34, timediff=7\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT1', current_instrument_name=INSTRUMENT1\n",
      "call_counter=13\n",
      "NEW Q 11/01/2024, 17:38:41, timediff=7\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT1', current_instrument_name=INSTRUMENT1\n",
      "call_counter=14\n",
      "NEW Q 11/01/2024, 17:38:48, timediff=7\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT1', current_instrument_name=INSTRUMENT1\n",
      "call_counter=15\n",
      "SAME Q 11/01/2024, 17:38:49, timediff=1\n",
      " \n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from random import randint\n",
    "\n",
    "query_db = query_db_closure(verbose=True)\n",
    "\n",
    "for instrument in dummy_instrument_list:\n",
    "    # artificial time delay\n",
    "    # in order to witness\n",
    "    # subsequent time intervals > 5secs\n",
    "    time.sleep(randint(1, 10))\n",
    "    _ = query_db(instrument)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "everything seems to be working as it should, we get a new query only if timediff>5secs which means 5 seconds pass after the previous query\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the same manner for random instruments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['INSTRUMENT2',\n",
       " 'INSTRUMENT2',\n",
       " 'INSTRUMENT2',\n",
       " 'INSTRUMENT1',\n",
       " 'INSTRUMENT3',\n",
       " 'INSTRUMENT1',\n",
       " 'INSTRUMENT2',\n",
       " 'INSTRUMENT3',\n",
       " 'INSTRUMENT3']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dummy_instrument_list = [f\"INSTRUMENT{choice([1,2,3])}\" for i in range(1, 10)]\n",
    "\n",
    "dummy_instrument_list: list[str] = [\n",
    "    \"INSTRUMENT2\",\n",
    "    \"INSTRUMENT2\",\n",
    "    \"INSTRUMENT2\",\n",
    "    \"INSTRUMENT1\",\n",
    "    \"INSTRUMENT3\",\n",
    "    \"INSTRUMENT1\",\n",
    "    \"INSTRUMENT2\",\n",
    "    \"INSTRUMENT3\",\n",
    "    \"INSTRUMENT3\",\n",
    "]\n",
    "\n",
    "dummy_instrument_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----query_db----\n",
      "last_instrument_name='', current_instrument_name=INSTRUMENT2\n",
      "call_counter=1\n",
      "NEW Q 11/01/2024, 17:38:55, timediff=6\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT2', current_instrument_name=INSTRUMENT2\n",
      "call_counter=2\n",
      "NEW Q 11/01/2024, 17:39:03, timediff=8\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT2', current_instrument_name=INSTRUMENT2\n",
      "call_counter=3\n",
      "NEW Q 11/01/2024, 17:39:11, timediff=8\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT2', current_instrument_name=INSTRUMENT1\n",
      "call_counter=4\n",
      "NEW Q 11/01/2024, 17:39:16, timediff=5\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT1', current_instrument_name=INSTRUMENT3\n",
      "call_counter=5\n",
      "NEW Q 11/01/2024, 17:39:22, timediff=6\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT3', current_instrument_name=INSTRUMENT1\n",
      "call_counter=6\n",
      "NEW Q 11/01/2024, 17:39:32, timediff=10\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT1', current_instrument_name=INSTRUMENT2\n",
      "call_counter=7\n",
      "NEW Q 11/01/2024, 17:39:34, timediff=2\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT2', current_instrument_name=INSTRUMENT3\n",
      "call_counter=8\n",
      "NEW Q 11/01/2024, 17:39:38, timediff=4\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT3', current_instrument_name=INSTRUMENT3\n",
      "call_counter=9\n",
      "NEW Q 11/01/2024, 17:39:48, timediff=10\n",
      " \n"
     ]
    }
   ],
   "source": [
    "query_db = query_db_closure(verbose=True)\n",
    "\n",
    "for instrument in dummy_instrument_list:\n",
    "    # artificial time delay\n",
    "    # in order to witness\n",
    "    # subsequent time intervals > 5secs\n",
    "    time.sleep(randint(1, 10))\n",
    "    _ = query_db(instrument)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see for different subsequent instrument names our closure works as intended without regard for the time constraint of 5 secs but it does respect it in case of same subsequent instruments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting everything together\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this code we expect multipliers only for INSTRUMENT2 since our data in the database has been engineered to not contain INSTRUMENT1, INSTRUMENT3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----query_db----\n",
      "last_instrument_name='', current_instrument_name=INSTRUMENT1\n",
      "call_counter=1\n",
      "NEW Q 11/01/2024, 17:39:49, timediff=1\n",
      " \n",
      "instrument='INSTRUMENT1'\n",
      "Initial value: 2.4655\n",
      "No Multiplier found\n",
      "final_value=2.4655\n",
      "\n",
      "\n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT1', current_instrument_name=INSTRUMENT1\n",
      "call_counter=2\n",
      "SAME Q 11/01/2024, 17:39:53, timediff=4\n",
      " \n",
      "instrument='INSTRUMENT1'\n",
      "Initial value: 2.4685\n",
      "No Multiplier found\n",
      "final_value=2.4685\n",
      "\n",
      "\n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT1', current_instrument_name=INSTRUMENT2\n",
      "call_counter=3\n",
      "NEW Q 11/01/2024, 17:39:59, timediff=6\n",
      " \n",
      "instrument='INSTRUMENT2'\n",
      "Initial value: 9.326787847\n",
      "Multiplier found: 4.4\n",
      "final_value=41.0378665268\n",
      "\n",
      "\n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT2', current_instrument_name=INSTRUMENT2\n",
      "call_counter=4\n",
      "SAME Q 11/01/2024, 17:40:04, timediff=5\n",
      " \n",
      "instrument='INSTRUMENT2'\n",
      "Initial value: 9.321527686\n",
      "Multiplier found: 4.4\n",
      "final_value=41.0147218184\n",
      "\n",
      "\n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT2', current_instrument_name=INSTRUMENT3\n",
      "call_counter=5\n",
      "NEW Q 11/01/2024, 17:40:11, timediff=7\n",
      " \n",
      "instrument='INSTRUMENT3'\n",
      "Initial value: 78.5325\n",
      "No Multiplier found\n",
      "final_value=78.5325\n",
      "\n",
      "\n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT3', current_instrument_name=INSTRUMENT3\n",
      "call_counter=6\n",
      "NEW Q 11/01/2024, 17:40:22, timediff=10\n",
      " \n",
      "instrument='INSTRUMENT3'\n",
      "Initial value: 78.2655\n",
      "No Multiplier found\n",
      "final_value=78.2655\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('INSTRUMENT1', 2.4655, 2.4655),\n",
       " ('INSTRUMENT1', 2.4685, 2.4685),\n",
       " ('INSTRUMENT2', 9.326787847, 41.0378665268),\n",
       " ('INSTRUMENT2', 9.321527686, 41.0147218184),\n",
       " ('INSTRUMENT3', 78.5325, 78.5325),\n",
       " ('INSTRUMENT3', 78.2655, 78.2655)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_db = query_db_closure(True)\n",
    "final_values = []\n",
    "\n",
    "for row in example_list:\n",
    "    # artificial time delay\n",
    "    # in order to witness\n",
    "    # subsequent time intervals > 5secs\n",
    "    time.sleep(randint(1, 10))\n",
    "\n",
    "    if instrument := row[\"INSTRUMENT_NAME\"]:\n",
    "        result_df = query_db(instrument)\n",
    "        old_value = row[\"VALUE\"]\n",
    "        print(f\"{instrument=}\")\n",
    "        print(f'Initial value: {old_value}')\n",
    "        \n",
    "        # is there is match in the database\n",
    "        if not result_df.isEmpty():\n",
    "            print(f\"Multiplier found: {result_df.collect()[0]['MULTIPLIER']}\")\n",
    "            final_value = old_value * result_df.collect()[0][\"MULTIPLIER\"]\n",
    "            print(f\"{final_value=}\")\n",
    "        # if there is no match in the database\n",
    "        else:\n",
    "            print(\"No Multiplier found\")\n",
    "            final_value = old_value\n",
    "            print(f\"{final_value=}\")\n",
    "        print(\"\\n\")\n",
    "        final_values.append((instrument, old_value, final_value))\n",
    "final_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we refactor and modularize the calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_value_calc_row(row, query_db):\n",
    "    '''row is read from the .txt file and query_db is the function coming from the closure query_db_closure'''\n",
    "    instrument = row['INSTRUMENT_NAME']\n",
    "    result_df = query_db(instrument)\n",
    "    old_value = row[\"VALUE\"]\n",
    "    \n",
    "    if result_df.isEmpty():\n",
    "        return old_value\n",
    "    return old_value * result_df.collect()[0][\"MULTIPLIER\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----query_db----\n",
      "last_instrument_name='', current_instrument_name=INSTRUMENT1\n",
      "call_counter=1\n",
      "NEW Q 11/01/2024, 18:42:41, timediff=2\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT1', current_instrument_name=INSTRUMENT1\n",
      "call_counter=2\n",
      "SAME Q 11/01/2024, 18:42:44, timediff=3\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT1', current_instrument_name=INSTRUMENT2\n",
      "call_counter=3\n",
      "NEW Q 11/01/2024, 18:42:54, timediff=10\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT2', current_instrument_name=INSTRUMENT2\n",
      "call_counter=4\n",
      "SAME Q 11/01/2024, 18:42:56, timediff=2\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT2', current_instrument_name=INSTRUMENT3\n",
      "call_counter=5\n",
      "NEW Q 11/01/2024, 18:43:02, timediff=6\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT3', current_instrument_name=INSTRUMENT3\n",
      "call_counter=6\n",
      "NEW Q 11/01/2024, 18:43:11, timediff=9\n",
      " \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.4655, 2.4685, 41.0378665268, 41.0147218184, 78.5325, 78.2655]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_db = query_db_closure(True)\n",
    "final_values = []\n",
    "\n",
    "for row in example_list:\n",
    "    time.sleep(randint(1, 10))\n",
    "\n",
    "    if instrument := row[\"INSTRUMENT_NAME\"]:\n",
    "        final_values.append(final_value_calc_row(row, query_db))\n",
    "        \n",
    "final_values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
