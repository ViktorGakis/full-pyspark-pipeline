{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from dotenv import load_dotenv\n",
    "from os import getenv\n",
    "from pathlib import Path\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "import findspark\n",
    "\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CWD: Path = Path(\"/app/\")\n",
    "EXAMPLE_INPUT_PATH: Path = CWD / Path(\"./coding_challenge_files/example_input.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAST PART TWO MYSQL DB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database Config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we setup the connector driver path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MYSQL_CONNECTOR_FILENAME: str = \"mysql-connector-j-8.2.0.jar\"\n",
    "MYSQL_CONNECTOR_PATH: str = f\"/app/mysql_connector/{MYSQL_CONNECTOR_FILENAME}\"\n",
    "TABLE_NAME: str = \"INSTRUMENT_PRICE_MODIFIER\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check if hte connector path is correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(MYSQL_CONNECTOR_PATH).exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we move the connector driver in the proper place in order to be recognizable by pyspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.add_jars(MYSQL_CONNECTOR_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We setup the relevant credentials for the database connection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user': 'root',\n",
       " 'password': 'example',\n",
       " 'host': 'db',\n",
       " 'port': 3306,\n",
       " 'database': 'mydb'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# database connection info\n",
    "DB_CON_DICT = dict(\n",
    "    user=getenv(\"MYSQL_ROOT_USER\"),\n",
    "    password=getenv(\"MYSQL_ROOT_PASSWORD\"),\n",
    "    host=getenv(\"HOST\"),\n",
    "    port=int(getenv(\"MYSQL_DOCKER_PORT\")),  # type: ignore\n",
    "    database=getenv(\"MYSQL_DATABASE\"),\n",
    ")\n",
    "\n",
    "DB_CON_DICT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also setup the pyspark specific format we need for the database connection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'driver': 'com.mysql.cj.jdbc.Driver',\n",
       " 'url': 'jdbc:mysql://db:3306/mydb',\n",
       " 'user': 'root',\n",
       " 'password': 'example'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure MySQL connection properties\n",
    "MYSQL_PROPERTIES = {\n",
    "    \"driver\": \"com.mysql.cj.jdbc.Driver\",\n",
    "    \"url\": \"jdbc:mysql://{host}:{port}/{database}\".format(**DB_CON_DICT),  # type: ignore\n",
    "    \"user\": DB_CON_DICT[\"user\"],  # type: ignore\n",
    "    \"password\": DB_CON_DICT[\"password\"],  # type: ignore\n",
    "}\n",
    "\n",
    "MYSQL_PROPERTIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test the database connection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tests.src import test_mysql_conx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection Success\n"
     ]
    }
   ],
   "source": [
    "# test database connection\n",
    "test_mysql_conx(**DB_CON_DICT)  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a test table with some values for pyspark database test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tests.src import table_preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'test_table' deleted successfully.\n",
      "Table 'test_table' created successfully.\n",
      "Sample data inserted successfully.\n"
     ]
    }
   ],
   "source": [
    "table_preparation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test the pyspark session against this test_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tests.src import test_pyspark_db_conx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MYSQL_PROPERTIES={'driver': 'com.mysql.cj.jdbc.Driver', 'url': 'jdbc:mysql://db:3306/mydb', 'user': 'root', 'password': 'example'}\n",
      "MYSQL driver path existence: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/01/11 13:57:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| id| name|\n",
      "+---+-----+\n",
      "|  1| John|\n",
      "|  2|Alice|\n",
      "|  3|  Bob|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_pyspark_db_conx()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We clean up the test_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tests.src import drop_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'test_table' deleted successfully.\n"
     ]
    }
   ],
   "source": [
    "drop_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `So as part of your task we would like you to set up a database with only one table, called INSTRUMENT_PRICE_MODIFIER with the following columns:`\n",
    "\n",
    "-   ID (primary key)\n",
    "-   NAME (instrument name as read from the input file)\n",
    "-   MULTIPLIER - double value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"DatabaseConnection\")\n",
    "    .config(\"spark.jars\", MYSQL_CONNECTOR_PATH)\n",
    "    .config(\"spark.driver.extraClassPath\", MYSQL_CONNECTOR_PATH)\n",
    "    .config(\"spark.executor.extraClassPath\", MYSQL_CONNECTOR_PATH)\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create the schema for the table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    IntegerType,\n",
    "    StringType,\n",
    "    DoubleType,\n",
    ")\n",
    "\n",
    "# Define the schema\n",
    "SCHEMA_DB = StructType(\n",
    "    [\n",
    "        StructField(\n",
    "            \"ID\", IntegerType(), False\n",
    "        ),  # False indicates that the field is not nullable\n",
    "        StructField(\n",
    "            \"NAME\", StringType(), True\n",
    "        ),  # True indicates that the field is nullable\n",
    "        StructField(\"MULTIPLIER\", DoubleType(), True),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing purposes we generate some dummy data, WITHOUT INSTRUMENT1 for the sake of realistic example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from random import uniform, randint\n",
    "\n",
    "# Generate test data\n",
    "# num_rows = 20\n",
    "# data = [\n",
    "#     (i, f\"INSTRUMENT{choice([2,4,5,6])}\", round(uniform(1.0, 10.0), 2))\n",
    "#     for i in range(1, num_rows + 1)\n",
    "# ]\n",
    "\n",
    "data: list[tuple[int, str, float]] = [\n",
    "    (1, \"INSTRUMENT5\", 5.19),\n",
    "    (2, \"INSTRUMENT4\", 5.05),\n",
    "    (3, \"INSTRUMENT2\", 4.4),\n",
    "    (4, \"INSTRUMENT4\", 2.25),\n",
    "    (5, \"INSTRUMENT5\", 1.75),\n",
    "    (6, \"INSTRUMENT6\", 9.91),\n",
    "    (7, \"INSTRUMENT4\", 4.5),\n",
    "    (8, \"INSTRUMENT2\", 9.24),\n",
    "    (9, \"INSTRUMENT6\", 5.83),\n",
    "    (10, \"INSTRUMENT5\", 1.34),\n",
    "    (11, \"INSTRUMENT6\", 8.89),\n",
    "    (12, \"INSTRUMENT2\", 2.59),\n",
    "    (13, \"INSTRUMENT5\", 4.04),\n",
    "    (14, \"INSTRUMENT4\", 8.58),\n",
    "    (15, \"INSTRUMENT2\", 8.64),\n",
    "    (16, \"INSTRUMENT2\", 3.99),\n",
    "    (17, \"INSTRUMENT2\", 6.82),\n",
    "    (18, \"INSTRUMENT2\", 7.7),\n",
    "    (19, \"INSTRUMENT4\", 4.44),\n",
    "    (20, \"INSTRUMENT4\", 8.01),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = false)\n",
      " |-- NAME: string (nullable = true)\n",
      " |-- MULTIPLIER: double (nullable = true)\n",
      "\n",
      "+---+-----------+----------+\n",
      "| ID|       NAME|MULTIPLIER|\n",
      "+---+-----------+----------+\n",
      "|  1|INSTRUMENT5|      5.19|\n",
      "|  2|INSTRUMENT4|      5.05|\n",
      "|  3|INSTRUMENT2|       4.4|\n",
      "|  4|INSTRUMENT4|      2.25|\n",
      "|  5|INSTRUMENT5|      1.75|\n",
      "+---+-----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(data, schema=SCHEMA_DB).orderBy(\"ID\")\n",
    "\n",
    "df.printSchema()\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the DataFrame to MySQL\n",
    "df.write.jdbc(\n",
    "    url=MYSQL_PROPERTIES[\"url\"],\n",
    "    table=TABLE_NAME,\n",
    "    mode=\"overwrite\",  # or \"append\" if needed\n",
    "    properties=MYSQL_PROPERTIES,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determination of the final value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 `read the line from the input file;`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the .txt file\n",
    "txt_file_path: str = f\"{EXAMPLE_INPUT_PATH}\"\n",
    "\n",
    "# Define the schema with StringType for DATE initially\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField(name=\"INSTRUMENT_NAME\", dataType=StringType(), nullable=True),\n",
    "        StructField(name=\"DATE\", dataType=StringType(), nullable=True),\n",
    "        StructField(name=\"VALUE\", dataType=DoubleType(), nullable=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Read the .txt file into a PySpark DataFrame\n",
    "extr = spark.read.option(\"delimiter\", \",\").csv(\n",
    "    txt_file_path, header=False, schema=schema\n",
    ")\n",
    "\n",
    "# transform to dataframe\n",
    "df_txt = extr.toDF(\"INSTRUMENT_NAME\", \"DATE\", \"VALUE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date\n",
    "\n",
    "date_format_str = \"dd-MMM-yyyy\"\n",
    "\n",
    "# Convert the string to a DateType using to_date function\n",
    "col_date_str = \"DATE\"\n",
    "col_transformed_to_date = \"DATE\"  # \"transformed_date\"\n",
    "col_formatted_Date = \"DATE\"  # \"formatted_date\"\n",
    "\n",
    "df_txt = df_txt.withColumn(\n",
    "    col_transformed_to_date, to_date(df_txt[col_date_str], date_format_str)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- INSTRUMENT_NAME: string (nullable = true)\n",
      " |-- DATE: date (nullable = true)\n",
      " |-- VALUE: double (nullable = true)\n",
      "\n",
      "+---------------+----------+------+\n",
      "|INSTRUMENT_NAME|      DATE| VALUE|\n",
      "+---------------+----------+------+\n",
      "|    INSTRUMENT1|1996-01-01|2.4655|\n",
      "|    INSTRUMENT1|1996-01-02|2.4685|\n",
      "|    INSTRUMENT1|1996-01-03| 2.473|\n",
      "|    INSTRUMENT1|1996-01-04|2.4845|\n",
      "|    INSTRUMENT1|1996-01-05|2.4868|\n",
      "+---------------+----------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_txt.printSchema()\n",
    "\n",
    "df_txt.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract all rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(INSTRUMENT_NAME='INSTRUMENT1', DATE=datetime.date(1996, 1, 1), VALUE=2.4655),\n",
       " Row(INSTRUMENT_NAME='INSTRUMENT1', DATE=datetime.date(1996, 1, 2), VALUE=2.4685),\n",
       " Row(INSTRUMENT_NAME='INSTRUMENT1', DATE=datetime.date(1996, 1, 3), VALUE=2.473),\n",
       " Row(INSTRUMENT_NAME='INSTRUMENT1', DATE=datetime.date(1996, 1, 4), VALUE=2.4845),\n",
       " Row(INSTRUMENT_NAME='INSTRUMENT1', DATE=datetime.date(1996, 1, 5), VALUE=2.4868)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = df_txt.collect()\n",
    "rows[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constructing the Solution\n",
    "\n",
    "`query the database to see if there is an entry for the <INSTRUMENT_NAME> you read in the 0st step;`\n",
    "\n",
    "`if there is - multiply the original <VALUE> by the factor you found in the step 2;`\n",
    "\n",
    "`if there is no entry - simply use the original <VALUE> from the file`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rough idea is the following for a couple of rows. For our example we cherry pick a couple of rows from each INSTRUMENT name we have on the .txt file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(INSTRUMENT_NAME='INSTRUMENT1', DATE=datetime.date(1996, 1, 1), VALUE=2.4655),\n",
       " Row(INSTRUMENT_NAME='INSTRUMENT1', DATE=datetime.date(1996, 1, 2), VALUE=2.4685)]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_1 = [row for row in rows if row[\"INSTRUMENT_NAME\"] == \"INSTRUMENT1\"][:2]\n",
    "l_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(INSTRUMENT_NAME='INSTRUMENT2', DATE=datetime.date(1996, 2, 22), VALUE=9.326787847),\n",
       " Row(INSTRUMENT_NAME='INSTRUMENT2', DATE=datetime.date(1996, 2, 23), VALUE=9.321527686)]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_2 = [row for row in rows if row[\"INSTRUMENT_NAME\"] == \"INSTRUMENT2\"][:2]\n",
    "l_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(INSTRUMENT_NAME='INSTRUMENT3', DATE=datetime.date(2012, 5, 31), VALUE=78.5325),\n",
       " Row(INSTRUMENT_NAME='INSTRUMENT3', DATE=datetime.date(2012, 6, 1), VALUE=78.2655)]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_3 = [row for row in rows if row[\"INSTRUMENT_NAME\"] == \"INSTRUMENT3\"][:2]\n",
    "l_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We engineered our database to not include INSTRUMENT1 for this example to be realistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='INSTRUMENT1'\n",
      "Initial value: 2.4655\n",
      "No Multiplier found\n",
      "final_value=2.4655\n",
      "-----------------------------\n",
      "name='INSTRUMENT1'\n",
      "Initial value: 2.4685\n",
      "No Multiplier found\n",
      "final_value=2.4685\n",
      "-----------------------------\n",
      "name='INSTRUMENT2'\n",
      "Initial value: 9.326787847\n",
      "Multiplier found: 4.4\n",
      "final_value=41.0378665268\n",
      "-----------------------------\n",
      "name='INSTRUMENT2'\n",
      "Initial value: 9.321527686\n",
      "Multiplier found: 4.4\n",
      "final_value=41.0147218184\n",
      "-----------------------------\n",
      "name='INSTRUMENT3'\n",
      "Initial value: 78.5325\n",
      "No Multiplier found\n",
      "final_value=78.5325\n",
      "-----------------------------\n",
      "name='INSTRUMENT3'\n",
      "Initial value: 78.2655\n",
      "No Multiplier found\n",
      "final_value=78.2655\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "# create an empty dataframe\n",
    "result_df = spark.createDataFrame([], schema=SCHEMA_DB)\n",
    "\n",
    "# let's see the first 10\n",
    "for row in l_1 + l_2 + l_3:\n",
    "\n",
    "    # check if the name is empty\n",
    "    if name := row[\"INSTRUMENT_NAME\"]:\n",
    "        # if not we proceed with querying the database\n",
    "        query: str = f\"SELECT * FROM {TABLE_NAME} WHERE NAME = '{name}'\"\n",
    "\n",
    "        # Query the database\n",
    "        result_df = (\n",
    "            spark.read.format(\"jdbc\").options(**MYSQL_PROPERTIES, query=query).load()\n",
    "        )\n",
    "        print(f\"{name=}\")\n",
    "        print(f'Initial value: {row[\"VALUE\"]}')\n",
    "\n",
    "    # is there is match in the database\n",
    "    if not result_df.isEmpty():\n",
    "        print(f\"Multiplier found: {result_df.collect()[0]['MULTIPLIER']}\")\n",
    "        final_value = row[\"VALUE\"] * result_df.collect()[0][\"MULTIPLIER\"]\n",
    "        print(f\"{final_value=}\")\n",
    "    # if there is no match in the database\n",
    "    else:\n",
    "        print(\"No Multiplier found\")\n",
    "        final_value = row[\"VALUE\"]\n",
    "        print(f\"{final_value=}\")\n",
    "    print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the rough idea works just fine. Let us refine it by properly introducing a proper  query mechanism according to the specifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the query is pretty simple and the table is supposed to be GBs it is much more efficient to directly query the database with the instrument name in order to obtain our result. \n",
    "- This really depends on how powerful is the pyspark cluster or the database itself.\n",
    "- We assume that direct query to the database consumes the least resources in this case.\n",
    "\n",
    "Regarding the time frequency of our queries, we will use a guard condition that will return the results of the previous query if we are within the 5 seconds time-window and the previous instrument name is the same as the current instrument name. Otherwise a new query will issued on the database.\n",
    "\n",
    "This construction will be realized using the notion of a closure. A closure very roughly is a function with memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "\n",
    "DB_MIN_UPDATE_TIME = 5  # secs\n",
    "\n",
    "\n",
    "def handle_query(instrument_name):\n",
    "    \"\"\"helper function to query a specific instrument in the db\"\"\"\n",
    "    query: str = f\"SELECT * FROM {TABLE_NAME} WHERE NAME = '{instrument_name}'\"\n",
    "\n",
    "    # Query the database\n",
    "    return spark.read.format(\"jdbc\").options(**MYSQL_PROPERTIES, query=query).load()\n",
    "\n",
    "\n",
    "def query_db_closure(verbose: bool = False):\n",
    "    result_df = spark.createDataFrame([], schema=SCHEMA_DB)\n",
    "    last_time: datetime = datetime.now(timezone.utc)\n",
    "    last_instrument_name: str = \"\"\n",
    "    call_counter = 1\n",
    "\n",
    "    def query_db(instrument_name: str):\n",
    "        # this is to make the variables\n",
    "        # available to the upper scope of\n",
    "        # which is query_db_closure\n",
    "        nonlocal result_df, last_time, last_instrument_name, call_counter\n",
    "\n",
    "        current_time: datetime = datetime.now(timezone.utc)\n",
    "        timediff: int = (current_time - last_time).seconds\n",
    "\n",
    "        # printing logs\n",
    "        if verbose:\n",
    "            print(\"----query_db----\")\n",
    "            print(f\"{last_instrument_name=}, current_instrument_name={instrument_name}\")\n",
    "            print(f\"{call_counter=}\")\n",
    "\n",
    "        # this is a guard condition that ensures\n",
    "        # we query the database a maximum of once\n",
    "        # every 5 seconds for the same instrument\n",
    "        if timediff <= DB_MIN_UPDATE_TIME and (last_instrument_name == instrument_name):\n",
    "            if verbose:\n",
    "                current_time_str: str = datetime.strftime(\n",
    "                    current_time, \"%d/%m/%Y, %H:%M:%S\"\n",
    "                )\n",
    "                print(f\"SAME Q {current_time_str}, {timediff=}\")\n",
    "                print(\" \")\n",
    "            last_time = current_time\n",
    "            last_instrument_name = instrument_name\n",
    "            call_counter += 1\n",
    "            return result_df\n",
    "\n",
    "        # printing logs\n",
    "        if verbose:\n",
    "            current_time_str: str = datetime.strftime(\n",
    "                current_time, \"%d/%m/%Y, %H:%M:%S\"\n",
    "            )\n",
    "            print(f\"NEW Q {current_time_str}, {timediff=}\")\n",
    "            print(\" \")\n",
    "\n",
    "        # query database\n",
    "        result_df = handle_query(instrument_name)\n",
    "\n",
    "        last_time = current_time\n",
    "        last_instrument_name = instrument_name\n",
    "        call_counter += 1\n",
    "        return result_df\n",
    "\n",
    "    return query_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this first with the exact same instruments all over\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['INSTRUMENT1',\n",
       " 'INSTRUMENT1',\n",
       " 'INSTRUMENT1',\n",
       " 'INSTRUMENT1',\n",
       " 'INSTRUMENT1',\n",
       " 'INSTRUMENT1',\n",
       " 'INSTRUMENT1',\n",
       " 'INSTRUMENT1',\n",
       " 'INSTRUMENT1',\n",
       " 'INSTRUMENT1',\n",
       " 'INSTRUMENT1',\n",
       " 'INSTRUMENT1',\n",
       " 'INSTRUMENT1',\n",
       " 'INSTRUMENT1',\n",
       " 'INSTRUMENT1']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dummy_instrument_list = [f\"INSTRUMENT{choice([1, 1])}\" for i in range(1, 100)]\n",
    "\n",
    "dummy_instrument_list: list[str] = [\n",
    "    \"INSTRUMENT1\",\n",
    "    \"INSTRUMENT1\",\n",
    "    \"INSTRUMENT1\",\n",
    "    \"INSTRUMENT1\",\n",
    "    \"INSTRUMENT1\",\n",
    "    \"INSTRUMENT1\",\n",
    "    \"INSTRUMENT1\",\n",
    "    \"INSTRUMENT1\",\n",
    "    \"INSTRUMENT1\",\n",
    "    \"INSTRUMENT1\",\n",
    "    \"INSTRUMENT1\",\n",
    "    \"INSTRUMENT1\",\n",
    "    \"INSTRUMENT1\",\n",
    "    \"INSTRUMENT1\",\n",
    "    \"INSTRUMENT1\",\n",
    "]\n",
    "\n",
    "dummy_instrument_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should encouter NEW Q (new querries) only when timediff > 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----query_db----\n",
      "last_instrument_name='', current_instrument_name=INSTRUMENT1\n",
      "call_counter=1\n",
      "NEW Q 11/01/2024, 16:22:44, timediff=6\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT1', current_instrument_name=INSTRUMENT1\n",
      "call_counter=2\n",
      "SAME Q 11/01/2024, 16:22:45, timediff=1\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT1', current_instrument_name=INSTRUMENT1\n",
      "call_counter=3\n",
      "SAME Q 11/01/2024, 16:22:49, timediff=4\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT1', current_instrument_name=INSTRUMENT1\n",
      "call_counter=4\n",
      "SAME Q 11/01/2024, 16:22:51, timediff=2\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT1', current_instrument_name=INSTRUMENT1\n",
      "call_counter=5\n",
      "SAME Q 11/01/2024, 16:22:54, timediff=3\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT1', current_instrument_name=INSTRUMENT1\n",
      "call_counter=6\n",
      "SAME Q 11/01/2024, 16:22:56, timediff=2\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT1', current_instrument_name=INSTRUMENT1\n",
      "call_counter=7\n",
      "NEW Q 11/01/2024, 16:23:02, timediff=6\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT1', current_instrument_name=INSTRUMENT1\n",
      "call_counter=8\n",
      "NEW Q 11/01/2024, 16:23:09, timediff=7\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT1', current_instrument_name=INSTRUMENT1\n",
      "call_counter=9\n",
      "NEW Q 11/01/2024, 16:23:17, timediff=8\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT1', current_instrument_name=INSTRUMENT1\n",
      "call_counter=10\n",
      "SAME Q 11/01/2024, 16:23:21, timediff=4\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT1', current_instrument_name=INSTRUMENT1\n",
      "call_counter=11\n",
      "SAME Q 11/01/2024, 16:23:24, timediff=3\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT1', current_instrument_name=INSTRUMENT1\n",
      "call_counter=12\n",
      "NEW Q 11/01/2024, 16:23:30, timediff=6\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT1', current_instrument_name=INSTRUMENT1\n",
      "call_counter=13\n",
      "SAME Q 11/01/2024, 16:23:35, timediff=4\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT1', current_instrument_name=INSTRUMENT1\n",
      "call_counter=14\n",
      "NEW Q 11/01/2024, 16:23:45, timediff=10\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT1', current_instrument_name=INSTRUMENT1\n",
      "call_counter=15\n",
      "SAME Q 11/01/2024, 16:23:49, timediff=4\n",
      " \n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "query_db = query_db_closure(verbose=True)\n",
    "\n",
    "for instrument in dummy_instrument_list:\n",
    "    time.sleep(randint(1, 10))\n",
    "    _ = query_db(instrument)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "everything seems to be working as it should, we get a new query only if timediff>5secs which means 5 seconds pass after the previous query\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the same manner for random instruments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['INSTRUMENT2',\n",
       " 'INSTRUMENT2',\n",
       " 'INSTRUMENT2',\n",
       " 'INSTRUMENT1',\n",
       " 'INSTRUMENT3',\n",
       " 'INSTRUMENT1',\n",
       " 'INSTRUMENT2',\n",
       " 'INSTRUMENT3',\n",
       " 'INSTRUMENT3']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dummy_instrument_list = [f\"INSTRUMENT{choice([1,2,3])}\" for i in range(1, 10)]\n",
    "\n",
    "dummy_instrument_list: list[str] = [\n",
    "    \"INSTRUMENT2\",\n",
    "    \"INSTRUMENT2\",\n",
    "    \"INSTRUMENT2\",\n",
    "    \"INSTRUMENT1\",\n",
    "    \"INSTRUMENT3\",\n",
    "    \"INSTRUMENT1\",\n",
    "    \"INSTRUMENT2\",\n",
    "    \"INSTRUMENT3\",\n",
    "    \"INSTRUMENT3\",\n",
    "]\n",
    "\n",
    "dummy_instrument_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----query_db----\n",
      "last_instrument_name='', current_instrument_name=INSTRUMENT2\n",
      "call_counter=1\n",
      "NEW Q 11/01/2024, 16:24:44, timediff=4\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT2', current_instrument_name=INSTRUMENT2\n",
      "call_counter=2\n",
      "NEW Q 11/01/2024, 16:24:52, timediff=8\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT2', current_instrument_name=INSTRUMENT2\n",
      "call_counter=3\n",
      "SAME Q 11/01/2024, 16:24:53, timediff=1\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT2', current_instrument_name=INSTRUMENT1\n",
      "call_counter=4\n",
      "NEW Q 11/01/2024, 16:25:03, timediff=10\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT1', current_instrument_name=INSTRUMENT3\n",
      "call_counter=5\n",
      "NEW Q 11/01/2024, 16:25:06, timediff=3\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT3', current_instrument_name=INSTRUMENT1\n",
      "call_counter=6\n",
      "NEW Q 11/01/2024, 16:25:13, timediff=7\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT1', current_instrument_name=INSTRUMENT2\n",
      "call_counter=7\n",
      "NEW Q 11/01/2024, 16:25:16, timediff=3\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT2', current_instrument_name=INSTRUMENT3\n",
      "call_counter=8\n",
      "NEW Q 11/01/2024, 16:25:19, timediff=3\n",
      " \n",
      "----query_db----\n",
      "last_instrument_name='INSTRUMENT3', current_instrument_name=INSTRUMENT3\n",
      "call_counter=9\n",
      "NEW Q 11/01/2024, 16:25:27, timediff=8\n",
      " \n"
     ]
    }
   ],
   "source": [
    "query_db = query_db_closure(verbose=True)\n",
    "\n",
    "for instrument in dummy_instrument_list:\n",
    "    time.sleep(randint(1, 10))\n",
    "    _ = query_db(instrument)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see for different subsequent instrument names our closure works as intended without regard for the time constraint of 5 secs but it does respect it in case of same subsequent instruments.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
