{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from dotenv import load_dotenv\n",
    "from os import getenv\n",
    "from pathlib import Path\n",
    "load_dotenv()\n",
    "\n",
    "import findspark\n",
    "\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CWD: Path = Path(\"/app/\")\n",
    "EXAMPLE_INPUT_PATH: Path = CWD / Path(\"./coding_challenge_files/example_input.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAST PART TWO MYSQL DB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database Config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we setup the connector driver path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MYSQL_CONNECTOR_FILENAME: str = \"mysql-connector-j-8.2.0.jar\"\n",
    "MYSQL_CONNECTOR_PATH: str = f\"/app/mysql_connector/{MYSQL_CONNECTOR_FILENAME}\"\n",
    "TABLE_NAME: str = \"INSTRUMENT_PRICE_MODIFIER\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check if hte connector path is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(MYSQL_CONNECTOR_PATH).exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we move the connector driver in the proper place in order to be recognizable by pyspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.add_jars(MYSQL_CONNECTOR_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We setup the relevant credentials for the database connection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user': 'root',\n",
       " 'password': 'example',\n",
       " 'host': 'db',\n",
       " 'port': 3306,\n",
       " 'database': 'mydb'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# database connection info\n",
    "DB_CON_DICT = dict(\n",
    "    user=getenv(\"MYSQL_ROOT_USER\"),\n",
    "    password=getenv(\"MYSQL_ROOT_PASSWORD\"),\n",
    "    host=getenv(\"HOST\"),\n",
    "    port=int(getenv(\"MYSQL_DOCKER_PORT\")), # type: ignore\n",
    "    database=getenv(\"MYSQL_DATABASE\"),\n",
    ")\n",
    "\n",
    "DB_CON_DICT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also setup the pyspark specific format we need for the database connection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'driver': 'com.mysql.cj.jdbc.Driver',\n",
       " 'url': 'jdbc:mysql://db:3306/mydb',\n",
       " 'user': 'root',\n",
       " 'password': 'example'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure MySQL connection properties\n",
    "MYSQL_PROPERTIES = {\n",
    "    \"driver\": \"com.mysql.cj.jdbc.Driver\",\n",
    "    \"url\": \"jdbc:mysql://{host}:{port}/{database}\".format(**DB_CON_DICT), # type: ignore\n",
    "    \"user\": DB_CON_DICT[\"user\"], # type: ignore\n",
    "    \"password\": DB_CON_DICT[\"password\"], # type: ignore\n",
    "}\n",
    "\n",
    "MYSQL_PROPERTIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test the database connection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tests import test_mysql_conx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection Success\n"
     ]
    }
   ],
   "source": [
    "# test database connection\n",
    "test_mysql_conx(**DB_CON_DICT) # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a test table with some values for pyspark database test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tests import table_preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'test_table' deleted successfully.\n",
      "Table 'test_table' created successfully.\n",
      "Sample data inserted successfully.\n"
     ]
    }
   ],
   "source": [
    "table_preparation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test the pyspark session against this test_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tests import test_pyspark_db_conx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MYSQL_PROPERTIES={'driver': 'com.mysql.cj.jdbc.Driver', 'url': 'jdbc:mysql://db:3306/mydb', 'user': 'root', 'password': 'example'}\n",
      "MYSQL driver path existence: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/01/11 12:55:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| id| name|\n",
      "+---+-----+\n",
      "|  1| John|\n",
      "|  2|Alice|\n",
      "|  3|  Bob|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_pyspark_db_conx()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We clean up the test_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tests import drop_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'test_table' deleted successfully.\n"
     ]
    }
   ],
   "source": [
    "drop_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `So as part of your task we would like you to set up a database with only one table, called INSTRUMENT_PRICE_MODIFIER with the following columns:`\n",
    "\n",
    "- ID (primary key)\n",
    "- NAME (instrument name as read from the input file)\n",
    "- MULTIPLIER - double value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
